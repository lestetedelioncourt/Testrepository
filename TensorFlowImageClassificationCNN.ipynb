{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0D7CaTaYmG_E"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(trainX, trainY), (testX, testY) = cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aHkHDU0o0k5",
        "outputId": "1a4b67c3-8fb7-4c44-8f41-1c12bbf15118"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX.shape, trainY.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWezzg8Oo7W4",
        "outputId": "d3376843-f203-486f-b97a-90d34c28a2eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testX.shape, testY.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRHnHUrEpfhE",
        "outputId": "b73ce652-f32f-479a-9b23-7c8b80014759"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 32, 32, 3), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10.load_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "pPijAroSpqQp",
        "outputId": "676a2d3b-94f0-46c2-da82-27c9d943ef21"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function keras.src.datasets.cifar10.load_data()>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>keras.src.datasets.cifar10.load_data</b><br/>def load_data()</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/keras/src/datasets/cifar10.py</a>Loads the CIFAR10 dataset.\n",
              "\n",
              "This is a dataset of 50,000 32x32 color training images and 10,000 test\n",
              "images, labeled over 10 categories. See more info at the\n",
              "[CIFAR homepage](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
              "\n",
              "The classes are:\n",
              "\n",
              "| Label | Description |\n",
              "|:-----:|-------------|\n",
              "|   0   | airplane    |\n",
              "|   1   | automobile  |\n",
              "|   2   | bird        |\n",
              "|   3   | cat         |\n",
              "|   4   | deer        |\n",
              "|   5   | dog         |\n",
              "|   6   | frog        |\n",
              "|   7   | horse       |\n",
              "|   8   | ship        |\n",
              "|   9   | truck       |\n",
              "\n",
              "Returns:\n",
              "  Tuple of NumPy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
              "\n",
              "**x_train**: uint8 NumPy array of image data with shapes\n",
              "  `(50000, 32, 32, 3)`, containing the training data. Pixel values range\n",
              "  from 0 to 255.\n",
              "\n",
              "**y_train**: uint8 NumPy array of labels (integers in range 0-9)\n",
              "  with shape `(50000, 1)` for the training data.\n",
              "\n",
              "**x_test**: uint8 NumPy array of image data with shapes\n",
              "  `(10000, 32, 32, 3)`, containing the test data. Pixel values range\n",
              "  from 0 to 255.\n",
              "\n",
              "**y_test**: uint8 NumPy array of labels (integers in range 0-9)\n",
              "  with shape `(10000, 1)` for the test data.\n",
              "\n",
              "Example:\n",
              "\n",
              "```python\n",
              "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
              "assert x_train.shape == (50000, 32, 32, 3)\n",
              "assert x_test.shape == (10000, 32, 32, 3)\n",
              "assert y_train.shape == (50000, 1)\n",
              "assert y_test.shape == (10000, 1)\n",
              "```</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 29);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainY = to_categorical(trainY)\n",
        "testY = to_categorical(testY)"
      ],
      "metadata": {
        "id": "pEUV5in6rHjX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX = trainX.astype('float32')\n",
        "testX = testX.astype('float32')\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0"
      ],
      "metadata": {
        "id": "I41mUYMcrZ4s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "t_CQUL-2s4zN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "rYXxXZdjtBDD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SORWBQyzypNC",
        "outputId": "6d2415b2-ee09-4131-e8f2-9f6804798ad3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 15, 15, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 64)          18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 3, 3, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 1, 1, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84554 (330.29 KB)\n",
            "Trainable params: 84554 (330.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vWWkX0X3ys7U"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=trainX, y=trainY, epochs=200, batch_size=20000, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA_CuseczLId",
        "outputId": "38cb8962-430c-4f9e-ee23-1f47dda9c5d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3/3 [==============================] - 24s 4s/step - loss: 2.3036 - accuracy: 0.1069\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 1s 298ms/step - loss: 2.2966 - accuracy: 0.1005\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 2.2835 - accuracy: 0.1232\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 1s 306ms/step - loss: 2.2555 - accuracy: 0.1756\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 1s 303ms/step - loss: 2.2203 - accuracy: 0.1827\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 1s 304ms/step - loss: 2.1850 - accuracy: 0.1969\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 1s 314ms/step - loss: 2.1448 - accuracy: 0.2266\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 2.1082 - accuracy: 0.2347\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 1s 349ms/step - loss: 2.0722 - accuracy: 0.2502\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 1s 352ms/step - loss: 2.0391 - accuracy: 0.2578\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 1s 306ms/step - loss: 2.0017 - accuracy: 0.2622\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 1.9705 - accuracy: 0.2684\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 1s 308ms/step - loss: 1.9549 - accuracy: 0.2741\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 1s 305ms/step - loss: 1.9339 - accuracy: 0.2787\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 1s 304ms/step - loss: 1.9020 - accuracy: 0.2840\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 1s 305ms/step - loss: 1.8877 - accuracy: 0.2939\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 1s 306ms/step - loss: 1.8624 - accuracy: 0.3006\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 1s 305ms/step - loss: 1.8391 - accuracy: 0.3081\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 1s 306ms/step - loss: 1.8202 - accuracy: 0.3190\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 1s 311ms/step - loss: 1.8041 - accuracy: 0.3242\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 1s 343ms/step - loss: 1.7823 - accuracy: 0.3307\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.7673 - accuracy: 0.3396\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 1s 347ms/step - loss: 1.9453 - accuracy: 0.2898\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 1s 312ms/step - loss: 1.8296 - accuracy: 0.3214\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 1s 312ms/step - loss: 1.7994 - accuracy: 0.3375\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 1s 310ms/step - loss: 1.7840 - accuracy: 0.3391\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 1s 307ms/step - loss: 1.7598 - accuracy: 0.3505\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 1s 309ms/step - loss: 1.7463 - accuracy: 0.3584\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 1s 304ms/step - loss: 1.7320 - accuracy: 0.3598\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 1s 311ms/step - loss: 1.7190 - accuracy: 0.3651\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 1s 308ms/step - loss: 1.7058 - accuracy: 0.3700\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 1s 307ms/step - loss: 1.6900 - accuracy: 0.3727\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.6785 - accuracy: 0.3781\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 1s 342ms/step - loss: 1.6656 - accuracy: 0.3815\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 1s 367ms/step - loss: 1.6519 - accuracy: 0.3882\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 1s 315ms/step - loss: 1.6400 - accuracy: 0.3907\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 1s 314ms/step - loss: 1.6285 - accuracy: 0.3950\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 1.6199 - accuracy: 0.3979\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.6268 - accuracy: 0.3966\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 1.6143 - accuracy: 0.3998\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 1s 309ms/step - loss: 1.6018 - accuracy: 0.4053\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 1.5998 - accuracy: 0.4080\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 1s 312ms/step - loss: 1.5845 - accuracy: 0.4137\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 1s 310ms/step - loss: 1.5688 - accuracy: 0.4181\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 1s 312ms/step - loss: 1.5586 - accuracy: 0.4218\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 1s 362ms/step - loss: 1.5511 - accuracy: 0.4237\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 1s 352ms/step - loss: 1.5449 - accuracy: 0.4272\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.5785 - accuracy: 0.4187\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 1.5556 - accuracy: 0.4235\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.5483 - accuracy: 0.4293\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 1s 315ms/step - loss: 1.5306 - accuracy: 0.4368\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 1.5179 - accuracy: 0.4430\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 1s 314ms/step - loss: 1.5044 - accuracy: 0.4443\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.4946 - accuracy: 0.4496\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 1.4852 - accuracy: 0.4527\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.4790 - accuracy: 0.4549\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.4896 - accuracy: 0.4526\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 1s 363ms/step - loss: 1.4820 - accuracy: 0.4539\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 1s 362ms/step - loss: 1.4848 - accuracy: 0.4548\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 1s 356ms/step - loss: 1.4667 - accuracy: 0.4584\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 1s 314ms/step - loss: 1.4827 - accuracy: 0.4562\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 1.4523 - accuracy: 0.4647\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 1s 308ms/step - loss: 1.4506 - accuracy: 0.4673\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 1s 315ms/step - loss: 1.4443 - accuracy: 0.4700\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 1.4322 - accuracy: 0.4736\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 1s 312ms/step - loss: 1.4286 - accuracy: 0.4748\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 1.4283 - accuracy: 0.4751\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.4135 - accuracy: 0.4807\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 1.4081 - accuracy: 0.4833\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 1s 382ms/step - loss: 1.4075 - accuracy: 0.4833\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 1s 342ms/step - loss: 1.4117 - accuracy: 0.4834\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 1s 339ms/step - loss: 1.3935 - accuracy: 0.4879\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 1s 311ms/step - loss: 1.3983 - accuracy: 0.4872\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 1.3885 - accuracy: 0.4889\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 1.3768 - accuracy: 0.4948\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 1.3884 - accuracy: 0.4915\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 1s 311ms/step - loss: 1.4019 - accuracy: 0.4867\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 1.3809 - accuracy: 0.4951\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 1.3791 - accuracy: 0.4962\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 1.3681 - accuracy: 0.5006\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 1.3592 - accuracy: 0.5029\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 1.3605 - accuracy: 0.5027\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 1s 369ms/step - loss: 1.3463 - accuracy: 0.5089\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 1s 350ms/step - loss: 1.3515 - accuracy: 0.5055\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 1s 314ms/step - loss: 1.3494 - accuracy: 0.5071\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 1s 311ms/step - loss: 1.3622 - accuracy: 0.5049\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 1s 309ms/step - loss: 1.3348 - accuracy: 0.5130\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 1.3333 - accuracy: 0.5131\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 1.3287 - accuracy: 0.5171\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 1.3163 - accuracy: 0.5219\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 1.3177 - accuracy: 0.5187\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 1s 312ms/step - loss: 1.3072 - accuracy: 0.5243\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 1s 311ms/step - loss: 1.3254 - accuracy: 0.5163\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 1.3170 - accuracy: 0.5196\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 1s 340ms/step - loss: 1.3180 - accuracy: 0.5199\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 1s 361ms/step - loss: 1.3124 - accuracy: 0.5227\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 1s 312ms/step - loss: 1.3070 - accuracy: 0.5266\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 1.3087 - accuracy: 0.5249\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.3089 - accuracy: 0.5246\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.2933 - accuracy: 0.5289\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.2953 - accuracy: 0.5334\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.2925 - accuracy: 0.5310\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.2835 - accuracy: 0.5342\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 1.2979 - accuracy: 0.5311\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.2774 - accuracy: 0.5356\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 1.2709 - accuracy: 0.5420\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.2985 - accuracy: 0.5317\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 1s 377ms/step - loss: 1.2687 - accuracy: 0.5403\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.2746 - accuracy: 0.5417\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.2752 - accuracy: 0.5372\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 1s 315ms/step - loss: 1.3169 - accuracy: 0.5241\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.4188 - accuracy: 0.4913\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.3925 - accuracy: 0.4998\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 1.3251 - accuracy: 0.5197\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.3067 - accuracy: 0.5251\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 1.2958 - accuracy: 0.5313\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 1s 312ms/step - loss: 1.2799 - accuracy: 0.5381\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 1.2699 - accuracy: 0.5410\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 1s 352ms/step - loss: 1.2590 - accuracy: 0.5445\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 1s 348ms/step - loss: 1.2486 - accuracy: 0.5493\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 1.2399 - accuracy: 0.5504\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.2320 - accuracy: 0.5547\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.2241 - accuracy: 0.5592\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 1.2243 - accuracy: 0.5585\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 1.2187 - accuracy: 0.5592\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.2242 - accuracy: 0.5610\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.2287 - accuracy: 0.5572\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 1.2109 - accuracy: 0.5633\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.2261 - accuracy: 0.5609\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 1.2194 - accuracy: 0.5617\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 1s 336ms/step - loss: 1.2042 - accuracy: 0.5675\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 1s 364ms/step - loss: 1.1950 - accuracy: 0.5713\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 1.1876 - accuracy: 0.5733\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.1850 - accuracy: 0.5745\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.1887 - accuracy: 0.5752\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 1.1802 - accuracy: 0.5763\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.1818 - accuracy: 0.5761\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 1s 315ms/step - loss: 1.1744 - accuracy: 0.5781\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 1.1681 - accuracy: 0.5817\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 1.1685 - accuracy: 0.5825\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 1.1672 - accuracy: 0.5822\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 1.1653 - accuracy: 0.5828\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 1s 390ms/step - loss: 1.1643 - accuracy: 0.5820\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 1s 403ms/step - loss: 1.1737 - accuracy: 0.5801\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.1675 - accuracy: 0.5801\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 1s 314ms/step - loss: 1.1749 - accuracy: 0.5784\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 1.1780 - accuracy: 0.5789\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.1916 - accuracy: 0.5745\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.1726 - accuracy: 0.5827\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.1620 - accuracy: 0.5854\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.1548 - accuracy: 0.5895\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.1483 - accuracy: 0.5910\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.1424 - accuracy: 0.5933\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 1s 343ms/step - loss: 1.1455 - accuracy: 0.5911\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 1s 381ms/step - loss: 1.1357 - accuracy: 0.5964\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 1s 341ms/step - loss: 1.1357 - accuracy: 0.5953\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 1s 363ms/step - loss: 1.1342 - accuracy: 0.5952\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 1.1340 - accuracy: 0.5942\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 1.1245 - accuracy: 0.5994\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.1203 - accuracy: 0.6004\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.1165 - accuracy: 0.6027\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 1.1140 - accuracy: 0.6032\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 1.1200 - accuracy: 0.6026\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.1133 - accuracy: 0.6042\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.1066 - accuracy: 0.6066\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.1219 - accuracy: 0.6001\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 1s 385ms/step - loss: 1.1073 - accuracy: 0.6059\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.1231 - accuracy: 0.5992\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 1.1184 - accuracy: 0.6025\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.1238 - accuracy: 0.5981\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 1.1348 - accuracy: 0.5942\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.1346 - accuracy: 0.5941\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.1281 - accuracy: 0.6001\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.1162 - accuracy: 0.6041\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 1.1182 - accuracy: 0.6019\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 1.1106 - accuracy: 0.6056\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.1047 - accuracy: 0.6082\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.0955 - accuracy: 0.6115\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 1.0914 - accuracy: 0.6135\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 1s 374ms/step - loss: 1.0837 - accuracy: 0.6133\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 1s 347ms/step - loss: 1.0824 - accuracy: 0.6162\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 1.0748 - accuracy: 0.6191\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 1.0780 - accuracy: 0.6177\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.0769 - accuracy: 0.6177\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 1.0817 - accuracy: 0.6169\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.0841 - accuracy: 0.6161\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.0862 - accuracy: 0.6147\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 1.0792 - accuracy: 0.6169\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 1s 330ms/step - loss: 1.0798 - accuracy: 0.6174\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.0742 - accuracy: 0.6195\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 1s 382ms/step - loss: 1.0777 - accuracy: 0.6185\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 1s 345ms/step - loss: 1.0704 - accuracy: 0.6215\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 1s 360ms/step - loss: 1.0843 - accuracy: 0.6151\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 1.0715 - accuracy: 0.6209\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 1.0719 - accuracy: 0.6217\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 1.0688 - accuracy: 0.6238\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 1.0620 - accuracy: 0.6235\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 1.0534 - accuracy: 0.6292\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 1.0453 - accuracy: 0.6305\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 1s 309ms/step - loss: 1.0487 - accuracy: 0.6283\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a4b84146560>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=trainX, y=trainY, epochs=500, batch_size=5000, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9Rt0XMS1IWc",
        "outputId": "45424688-e6b3-4977-9c69-85d0c1505331"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "10/10 [==============================] - 5s 119ms/step - loss: 1.0701 - accuracy: 0.6190\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 1.0736 - accuracy: 0.6197\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 1.0530 - accuracy: 0.6283\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 1.0594 - accuracy: 0.6255\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 1.0350 - accuracy: 0.6324\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 1.0426 - accuracy: 0.6294\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 1.0671 - accuracy: 0.6255\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 1.0852 - accuracy: 0.6187\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 1.0401 - accuracy: 0.6333\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 1.0234 - accuracy: 0.6384\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 1.0211 - accuracy: 0.6377\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 1.0118 - accuracy: 0.6429\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 1.0017 - accuracy: 0.6461\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 1.0057 - accuracy: 0.6440\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 1.0014 - accuracy: 0.6456\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.9895 - accuracy: 0.6495\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.9784 - accuracy: 0.6565\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.9735 - accuracy: 0.6565\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.9687 - accuracy: 0.6578\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.9670 - accuracy: 0.6590\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - 1s 101ms/step - loss: 0.9640 - accuracy: 0.6599\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.9620 - accuracy: 0.6609\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.9555 - accuracy: 0.6625\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.9668 - accuracy: 0.6592\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.9522 - accuracy: 0.6635\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 0.9711 - accuracy: 0.6564\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.9631 - accuracy: 0.6610\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.9465 - accuracy: 0.6670\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.9442 - accuracy: 0.6689\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.9530 - accuracy: 0.6649\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.9274 - accuracy: 0.6736\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.9283 - accuracy: 0.6725\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.9237 - accuracy: 0.6749\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.9121 - accuracy: 0.6800\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.9145 - accuracy: 0.6798\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.9365 - accuracy: 0.6682\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 0.9348 - accuracy: 0.6726\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.9259 - accuracy: 0.6755\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.9278 - accuracy: 0.6743\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.9172 - accuracy: 0.6776\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.9072 - accuracy: 0.6822\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.8970 - accuracy: 0.6867\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.8862 - accuracy: 0.6893\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.8890 - accuracy: 0.6870\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.8953 - accuracy: 0.6866\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.8966 - accuracy: 0.6854\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.8942 - accuracy: 0.6872\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.8689 - accuracy: 0.6955\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.8743 - accuracy: 0.6925\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.9083 - accuracy: 0.6825\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 0.8943 - accuracy: 0.6874\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 0.8724 - accuracy: 0.6938\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.8694 - accuracy: 0.6964\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.8632 - accuracy: 0.6991\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.8477 - accuracy: 0.7032\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.8549 - accuracy: 0.7010\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.8395 - accuracy: 0.7062\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.8434 - accuracy: 0.7043\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.8577 - accuracy: 0.7003\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.8677 - accuracy: 0.6967\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.8384 - accuracy: 0.7080\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.8244 - accuracy: 0.7107\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.8264 - accuracy: 0.7100\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.8247 - accuracy: 0.7114\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.8285 - accuracy: 0.7106\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.8427 - accuracy: 0.7064\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.8586 - accuracy: 0.7000\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.8349 - accuracy: 0.7080\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - 1s 102ms/step - loss: 0.8238 - accuracy: 0.7101\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.8153 - accuracy: 0.7161\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.8014 - accuracy: 0.7192\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.8073 - accuracy: 0.7188\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.8149 - accuracy: 0.7130\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.8290 - accuracy: 0.7092\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.8107 - accuracy: 0.7157\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.8047 - accuracy: 0.7187\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 0.7974 - accuracy: 0.7209\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.8102 - accuracy: 0.7161\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.8236 - accuracy: 0.7130\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.8022 - accuracy: 0.7198\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7875 - accuracy: 0.7256\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.7845 - accuracy: 0.7259\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7898 - accuracy: 0.7240\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.7869 - accuracy: 0.7257\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.7759 - accuracy: 0.7299\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.7821 - accuracy: 0.7264\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 0.7974 - accuracy: 0.7201\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 0.7753 - accuracy: 0.7290\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 0.7729 - accuracy: 0.7302\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7661 - accuracy: 0.7330\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.7593 - accuracy: 0.7356\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.7620 - accuracy: 0.7345\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7939 - accuracy: 0.7222\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.7726 - accuracy: 0.7314\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.7720 - accuracy: 0.7313\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7597 - accuracy: 0.7340\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.7536 - accuracy: 0.7386\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.7416 - accuracy: 0.7418\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.7434 - accuracy: 0.7407\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 0.7399 - accuracy: 0.7423\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.7443 - accuracy: 0.7387\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.7686 - accuracy: 0.7296\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7493 - accuracy: 0.7383\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.7291 - accuracy: 0.7464\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - 1s 103ms/step - loss: 0.7282 - accuracy: 0.7472\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7334 - accuracy: 0.7454\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7230 - accuracy: 0.7488\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7266 - accuracy: 0.7470\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.7221 - accuracy: 0.7498\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.7336 - accuracy: 0.7444\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.7322 - accuracy: 0.7433\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 0.7350 - accuracy: 0.7446\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.7562 - accuracy: 0.7349\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7356 - accuracy: 0.7419\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7282 - accuracy: 0.7449\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7114 - accuracy: 0.7524\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.7022 - accuracy: 0.7568\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.7097 - accuracy: 0.7529\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.7231 - accuracy: 0.7489\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7104 - accuracy: 0.7520\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.7023 - accuracy: 0.7547\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.7122 - accuracy: 0.7514\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.6951 - accuracy: 0.7592\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 0.6852 - accuracy: 0.7621\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.6897 - accuracy: 0.7599\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.6841 - accuracy: 0.7608\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.6905 - accuracy: 0.7600\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.7133 - accuracy: 0.7500\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7074 - accuracy: 0.7534\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7453 - accuracy: 0.7396\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.7064 - accuracy: 0.7548\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.6834 - accuracy: 0.7631\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.6801 - accuracy: 0.7659\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.6748 - accuracy: 0.7655\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.6790 - accuracy: 0.7637\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - 1s 138ms/step - loss: 0.6810 - accuracy: 0.7626\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - 2s 151ms/step - loss: 0.6857 - accuracy: 0.7611\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - 1s 140ms/step - loss: 0.6775 - accuracy: 0.7647\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 0.6742 - accuracy: 0.7664\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.6963 - accuracy: 0.7580\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.6751 - accuracy: 0.7643\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.6619 - accuracy: 0.7707\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.6540 - accuracy: 0.7751\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.6602 - accuracy: 0.7709\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.6758 - accuracy: 0.7654\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.7127 - accuracy: 0.7488\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.6671 - accuracy: 0.7682\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - 1s 134ms/step - loss: 0.6550 - accuracy: 0.7731\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.6452 - accuracy: 0.7764\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.6453 - accuracy: 0.7748\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.6516 - accuracy: 0.7739\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.6469 - accuracy: 0.7743\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.6408 - accuracy: 0.7780\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.6439 - accuracy: 0.7761\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.6418 - accuracy: 0.7782\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.6402 - accuracy: 0.7801\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.6391 - accuracy: 0.7787\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.6402 - accuracy: 0.7777\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 0.6506 - accuracy: 0.7742\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.6734 - accuracy: 0.7651\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.6425 - accuracy: 0.7765\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.6311 - accuracy: 0.7811\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.6288 - accuracy: 0.7816\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.6145 - accuracy: 0.7880\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.6198 - accuracy: 0.7853\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.6172 - accuracy: 0.7864\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.6241 - accuracy: 0.7834\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.6699 - accuracy: 0.7652\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.6452 - accuracy: 0.7763\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.6298 - accuracy: 0.7827\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.6241 - accuracy: 0.7832\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - 1s 136ms/step - loss: 0.6232 - accuracy: 0.7855\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.6132 - accuracy: 0.7891\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.6015 - accuracy: 0.7930\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.6051 - accuracy: 0.7900\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.6028 - accuracy: 0.7910\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.5979 - accuracy: 0.7939\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.5956 - accuracy: 0.7937\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.5996 - accuracy: 0.7920\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.6000 - accuracy: 0.7914\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.6290 - accuracy: 0.7815\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.6002 - accuracy: 0.7914\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.5953 - accuracy: 0.7943\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 0.6000 - accuracy: 0.7922\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.6191 - accuracy: 0.7837\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.6449 - accuracy: 0.7754\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.6293 - accuracy: 0.7800\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.6158 - accuracy: 0.7857\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.5965 - accuracy: 0.7948\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.5864 - accuracy: 0.7976\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.5906 - accuracy: 0.7962\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.5855 - accuracy: 0.7980\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.5786 - accuracy: 0.7998\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.5785 - accuracy: 0.8000\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - 1s 132ms/step - loss: 0.5789 - accuracy: 0.7989\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - 1s 145ms/step - loss: 0.5709 - accuracy: 0.8033\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - 1s 145ms/step - loss: 0.5726 - accuracy: 0.8014\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.5697 - accuracy: 0.8022\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.5954 - accuracy: 0.7940\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 0.5810 - accuracy: 0.7989\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.5728 - accuracy: 0.8012\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - 1s 104ms/step - loss: 0.5806 - accuracy: 0.8000\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.5708 - accuracy: 0.8025\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.5504 - accuracy: 0.8123\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.5511 - accuracy: 0.8113\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.5535 - accuracy: 0.8103\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.5632 - accuracy: 0.8046\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.6044 - accuracy: 0.7890\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.5948 - accuracy: 0.7928\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.5693 - accuracy: 0.8028\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.5605 - accuracy: 0.8056\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.5652 - accuracy: 0.8041\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.5650 - accuracy: 0.8033\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.5459 - accuracy: 0.8121\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.5439 - accuracy: 0.8120\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.5462 - accuracy: 0.8114\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.5426 - accuracy: 0.8115\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - 1s 152ms/step - loss: 0.5362 - accuracy: 0.8153\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - 2s 161ms/step - loss: 0.5387 - accuracy: 0.8156\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - 1s 136ms/step - loss: 0.5349 - accuracy: 0.8170\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.5423 - accuracy: 0.8128\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.5389 - accuracy: 0.8137\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.5415 - accuracy: 0.8126\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.5298 - accuracy: 0.8163\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.5310 - accuracy: 0.8176\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.5317 - accuracy: 0.8165\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.5257 - accuracy: 0.8182\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.5515 - accuracy: 0.8080\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - 1s 131ms/step - loss: 0.5441 - accuracy: 0.8106\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - 1s 138ms/step - loss: 0.5346 - accuracy: 0.8142\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 0.5284 - accuracy: 0.8178\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.5283 - accuracy: 0.8165\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.5471 - accuracy: 0.8103\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.5287 - accuracy: 0.8170\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.5243 - accuracy: 0.8181\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 0.5208 - accuracy: 0.8199\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.5346 - accuracy: 0.8139\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.5072 - accuracy: 0.8262\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.5117 - accuracy: 0.8242\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.5482 - accuracy: 0.8105\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - 1s 135ms/step - loss: 0.5406 - accuracy: 0.8132\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.5153 - accuracy: 0.8209\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.5141 - accuracy: 0.8211\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.5081 - accuracy: 0.8253\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.5016 - accuracy: 0.8287\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.5168 - accuracy: 0.8210\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.5051 - accuracy: 0.8256\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.4906 - accuracy: 0.8304\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4918 - accuracy: 0.8317\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.4969 - accuracy: 0.8290\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.4997 - accuracy: 0.8279\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4980 - accuracy: 0.8298\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - 1s 134ms/step - loss: 0.4903 - accuracy: 0.8316\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.5087 - accuracy: 0.8238\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 0.6130 - accuracy: 0.7861\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.5268 - accuracy: 0.8174\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.4890 - accuracy: 0.8316\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4871 - accuracy: 0.8327\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4961 - accuracy: 0.8284\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4995 - accuracy: 0.8246\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4988 - accuracy: 0.8264\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.5189 - accuracy: 0.8182\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.5020 - accuracy: 0.8249\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4773 - accuracy: 0.8359\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 0.4761 - accuracy: 0.8359\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - 1s 130ms/step - loss: 0.4826 - accuracy: 0.8345\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 0.4793 - accuracy: 0.8368\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.4717 - accuracy: 0.8385\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.4786 - accuracy: 0.8351\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.4603 - accuracy: 0.8425\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4628 - accuracy: 0.8410\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4821 - accuracy: 0.8314\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.5507 - accuracy: 0.8070\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.5648 - accuracy: 0.7996\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.4898 - accuracy: 0.8304\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.4694 - accuracy: 0.8388\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.4581 - accuracy: 0.8432\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.4774 - accuracy: 0.8347\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 0.4544 - accuracy: 0.8456\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4605 - accuracy: 0.8422\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.4750 - accuracy: 0.8349\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4523 - accuracy: 0.8446\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4610 - accuracy: 0.8417\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4596 - accuracy: 0.8411\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.4548 - accuracy: 0.8443\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4558 - accuracy: 0.8433\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.4702 - accuracy: 0.8374\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.4541 - accuracy: 0.8425\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.4349 - accuracy: 0.8516\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.4477 - accuracy: 0.8458\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.4661 - accuracy: 0.8379\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.4678 - accuracy: 0.8368\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.4879 - accuracy: 0.8283\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.4672 - accuracy: 0.8382\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.4450 - accuracy: 0.8478\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4421 - accuracy: 0.8471\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4352 - accuracy: 0.8506\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.4359 - accuracy: 0.8517\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.4538 - accuracy: 0.8425\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.4489 - accuracy: 0.8451\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4402 - accuracy: 0.8481\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.4511 - accuracy: 0.8432\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.4618 - accuracy: 0.8382\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4374 - accuracy: 0.8496\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.4204 - accuracy: 0.8583\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.4132 - accuracy: 0.8603\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.4148 - accuracy: 0.8597\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 0.4161 - accuracy: 0.8584\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4343 - accuracy: 0.8505\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.4589 - accuracy: 0.8398\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4527 - accuracy: 0.8413\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.4517 - accuracy: 0.8424\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 0.4379 - accuracy: 0.8483\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4521 - accuracy: 0.8433\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.4628 - accuracy: 0.8375\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.4267 - accuracy: 0.8526\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.4278 - accuracy: 0.8527\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4237 - accuracy: 0.8533\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4241 - accuracy: 0.8542\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4109 - accuracy: 0.8599\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.4089 - accuracy: 0.8605\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4337 - accuracy: 0.8492\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4098 - accuracy: 0.8599\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.4119 - accuracy: 0.8584\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.4164 - accuracy: 0.8573\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - 1s 137ms/step - loss: 0.3982 - accuracy: 0.8660\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.3973 - accuracy: 0.8643\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4066 - accuracy: 0.8616\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.4314 - accuracy: 0.8500\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4076 - accuracy: 0.8599\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3985 - accuracy: 0.8652\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.3927 - accuracy: 0.8672\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.4074 - accuracy: 0.8590\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4318 - accuracy: 0.8489\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4149 - accuracy: 0.8553\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 0.3961 - accuracy: 0.8646\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3903 - accuracy: 0.8662\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.3979 - accuracy: 0.8640\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.3967 - accuracy: 0.8637\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.3915 - accuracy: 0.8661\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3911 - accuracy: 0.8661\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4008 - accuracy: 0.8618\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4376 - accuracy: 0.8467\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.3937 - accuracy: 0.8653\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4127 - accuracy: 0.8560\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4058 - accuracy: 0.8593\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.3933 - accuracy: 0.8635\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3901 - accuracy: 0.8666\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - 1s 138ms/step - loss: 0.3938 - accuracy: 0.8637\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - 1s 141ms/step - loss: 0.3950 - accuracy: 0.8633\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.5519 - accuracy: 0.8086\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4865 - accuracy: 0.8248\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.4336 - accuracy: 0.8473\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3900 - accuracy: 0.8656\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.3817 - accuracy: 0.8712\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 0.3819 - accuracy: 0.8708\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.3729 - accuracy: 0.8737\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.3592 - accuracy: 0.8805\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.3631 - accuracy: 0.8785\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - 1s 150ms/step - loss: 0.3691 - accuracy: 0.8756\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.3677 - accuracy: 0.8745\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.3613 - accuracy: 0.8788\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.3688 - accuracy: 0.8742\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.4553 - accuracy: 0.8375\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4436 - accuracy: 0.8411\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.3803 - accuracy: 0.8686\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3594 - accuracy: 0.8780\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.3504 - accuracy: 0.8833\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.3468 - accuracy: 0.8848\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3486 - accuracy: 0.8839\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.3552 - accuracy: 0.8800\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - 1s 129ms/step - loss: 0.3738 - accuracy: 0.8716\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3726 - accuracy: 0.8717\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.3645 - accuracy: 0.8749\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3663 - accuracy: 0.8751\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.3796 - accuracy: 0.8678\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3634 - accuracy: 0.8756\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.3617 - accuracy: 0.8765\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.3515 - accuracy: 0.8809\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.3577 - accuracy: 0.8770\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.3637 - accuracy: 0.8759\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.3451 - accuracy: 0.8844\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.3481 - accuracy: 0.8822\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3364 - accuracy: 0.8879\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - 1s 131ms/step - loss: 0.3313 - accuracy: 0.8902\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 0.3312 - accuracy: 0.8907\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.3348 - accuracy: 0.8887\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.3339 - accuracy: 0.8880\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3360 - accuracy: 0.8870\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.3595 - accuracy: 0.8769\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.3893 - accuracy: 0.8616\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.3641 - accuracy: 0.8743\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.3862 - accuracy: 0.8634\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.3914 - accuracy: 0.8618\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.3490 - accuracy: 0.8793\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - 1s 128ms/step - loss: 0.3402 - accuracy: 0.8840\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.3368 - accuracy: 0.8864\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.3677 - accuracy: 0.8707\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4156 - accuracy: 0.8522\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3649 - accuracy: 0.8741\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3452 - accuracy: 0.8821\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.3413 - accuracy: 0.8828\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.3289 - accuracy: 0.8907\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.3313 - accuracy: 0.8872\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.3347 - accuracy: 0.8855\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.3403 - accuracy: 0.8842\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 0.3315 - accuracy: 0.8861\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.3264 - accuracy: 0.8891\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.3307 - accuracy: 0.8870\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.3151 - accuracy: 0.8945\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.3113 - accuracy: 0.8962\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3142 - accuracy: 0.8961\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.3353 - accuracy: 0.8848\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3344 - accuracy: 0.8836\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3328 - accuracy: 0.8858\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.3157 - accuracy: 0.8934\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.3128 - accuracy: 0.8951\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3572 - accuracy: 0.8754\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.3286 - accuracy: 0.8869\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.3357 - accuracy: 0.8825\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.3448 - accuracy: 0.8808\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.3184 - accuracy: 0.8925\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.3207 - accuracy: 0.8903\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.3344 - accuracy: 0.8841\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.3314 - accuracy: 0.8860\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3138 - accuracy: 0.8927\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.3014 - accuracy: 0.9002\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.3042 - accuracy: 0.8978\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.3141 - accuracy: 0.8917\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.4076 - accuracy: 0.8568\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 0.4632 - accuracy: 0.8360\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3488 - accuracy: 0.8786\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3199 - accuracy: 0.8918\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 0.3111 - accuracy: 0.8938\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.3046 - accuracy: 0.8978\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.2901 - accuracy: 0.9051\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.2952 - accuracy: 0.9020\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.2920 - accuracy: 0.9037\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.2906 - accuracy: 0.9036\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.3122 - accuracy: 0.8918\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.3093 - accuracy: 0.8944\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.2973 - accuracy: 0.9001\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - 1s 115ms/step - loss: 0.2981 - accuracy: 0.9007\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - 1s 126ms/step - loss: 0.2932 - accuracy: 0.9010\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 0.3277 - accuracy: 0.8854\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.3559 - accuracy: 0.8730\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 0.3121 - accuracy: 0.8932\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.2909 - accuracy: 0.9031\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.2987 - accuracy: 0.8981\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.2910 - accuracy: 0.9015\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.2788 - accuracy: 0.9093\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.2829 - accuracy: 0.9064\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.2893 - accuracy: 0.9030\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.3217 - accuracy: 0.8858\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - 1s 125ms/step - loss: 0.3083 - accuracy: 0.8939\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 0.2799 - accuracy: 0.9069\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 0.2720 - accuracy: 0.9106\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.2819 - accuracy: 0.9045\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.2689 - accuracy: 0.9128\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.2737 - accuracy: 0.9100\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.2649 - accuracy: 0.9135\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.2649 - accuracy: 0.9135\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.2661 - accuracy: 0.9127\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.2805 - accuracy: 0.9055\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.2836 - accuracy: 0.9041\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - 1s 118ms/step - loss: 0.2795 - accuracy: 0.9044\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - 1s 136ms/step - loss: 0.2804 - accuracy: 0.9057\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - 1s 127ms/step - loss: 0.2840 - accuracy: 0.9024\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.2881 - accuracy: 0.8998\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.2985 - accuracy: 0.8969\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.2877 - accuracy: 0.8995\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.2766 - accuracy: 0.9061\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.3089 - accuracy: 0.8909\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.2956 - accuracy: 0.8983\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.2991 - accuracy: 0.8942\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.3130 - accuracy: 0.8904\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.2835 - accuracy: 0.9034\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 0.2628 - accuracy: 0.9129\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.2695 - accuracy: 0.9085\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2501 - accuracy: 0.9200\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.2469 - accuracy: 0.9213\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.2540 - accuracy: 0.9175\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.2531 - accuracy: 0.9171\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.2487 - accuracy: 0.9204\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.2458 - accuracy: 0.9214\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.2576 - accuracy: 0.9145\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.2538 - accuracy: 0.9153\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.2530 - accuracy: 0.9166\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - 1s 110ms/step - loss: 0.2544 - accuracy: 0.9154\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - 1s 124ms/step - loss: 0.2623 - accuracy: 0.9125\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - 1s 123ms/step - loss: 0.2969 - accuracy: 0.8960\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - 1s 119ms/step - loss: 0.3590 - accuracy: 0.8707\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - 1s 108ms/step - loss: 0.3178 - accuracy: 0.8851\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - 1s 109ms/step - loss: 0.3105 - accuracy: 0.8875\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.2722 - accuracy: 0.9068\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.2522 - accuracy: 0.9168\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - 1s 107ms/step - loss: 0.2610 - accuracy: 0.9123\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.2841 - accuracy: 0.9000\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - 1s 106ms/step - loss: 0.3109 - accuracy: 0.8879\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - 1s 105ms/step - loss: 0.2590 - accuracy: 0.9128\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a4b7c5526e0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "model_json = model.to_json()\n",
        "\n",
        "# with context manager probably means we do not have to call json_file.close() method here\n",
        "with open('model.json', 'w') as json_file:\n",
        "  json_file.write(model_json)\n",
        "\n",
        "  model.save_weights('model.h5')"
      ],
      "metadata": {
        "id": "o3C8x2pS3MGE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)"
      ],
      "metadata": {
        "id": "3IbZxcm54jwh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLdrSXgz52I7",
        "outputId": "d2217916-109b-4e99-b586-09661444e456"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 15, 15, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 64)          18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 3, 3, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 1, 1, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84554 (330.29 KB)\n",
            "Trainable params: 84554 (330.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to train model afresh can use loaded_model.compiie(), or simply use pretrained model weights\n",
        "\n",
        "loaded_model.load_weights('model.h5')"
      ],
      "metadata": {
        "id": "yWcd2m5y57iV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = loaded_model.predict(testX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rErxaW287My",
        "outputId": "970da439-735b-417d-cde9-cda8072a4e6c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "labels_test_predicted = np.argmax(p, 1)\n",
        "\n",
        "labels_test_predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_Tsax5G9E-1",
        "outputId": "1c7ea9a1-ef51-4701-c50f-1c787784f95b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 8, 9, ..., 5, 1, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(np.argmax(testY, axis=1), labels_test_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "YJpaM8nw9ZK2",
        "outputId": "3a58573a-1481-409d-c5ed-29386152087a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "col_0    0    1    2    3    4    5    6    7    8    9\n",
              "row_0                                                  \n",
              "0      717   16   68   23   31   13   17   21   54   40\n",
              "1       21  748    8   10    7    4   20   13   25  144\n",
              "2       55    9  575   70   69   66   71   62   14    9\n",
              "3       20    5   68  471   65  191   83   67   13   17\n",
              "4       12    4   82   69  609   51   69   89   10    5\n",
              "5       14    2   60  146   35  617   36   75    4   11\n",
              "6        7    2   58   63   38   23  786   13    3    7\n",
              "7       19    1   25   22   46   67   10  792    1   17\n",
              "8       62   33   21   25    7    6    6    9  787   44\n",
              "9       31   61    8   13    2   15   11   34   26  799"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d460328e-c5ad-465b-b89b-2a6119e35204\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>717</td>\n",
              "      <td>16</td>\n",
              "      <td>68</td>\n",
              "      <td>23</td>\n",
              "      <td>31</td>\n",
              "      <td>13</td>\n",
              "      <td>17</td>\n",
              "      <td>21</td>\n",
              "      <td>54</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>748</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>13</td>\n",
              "      <td>25</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>55</td>\n",
              "      <td>9</td>\n",
              "      <td>575</td>\n",
              "      <td>70</td>\n",
              "      <td>69</td>\n",
              "      <td>66</td>\n",
              "      <td>71</td>\n",
              "      <td>62</td>\n",
              "      <td>14</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>68</td>\n",
              "      <td>471</td>\n",
              "      <td>65</td>\n",
              "      <td>191</td>\n",
              "      <td>83</td>\n",
              "      <td>67</td>\n",
              "      <td>13</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>82</td>\n",
              "      <td>69</td>\n",
              "      <td>609</td>\n",
              "      <td>51</td>\n",
              "      <td>69</td>\n",
              "      <td>89</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>60</td>\n",
              "      <td>146</td>\n",
              "      <td>35</td>\n",
              "      <td>617</td>\n",
              "      <td>36</td>\n",
              "      <td>75</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>58</td>\n",
              "      <td>63</td>\n",
              "      <td>38</td>\n",
              "      <td>23</td>\n",
              "      <td>786</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>22</td>\n",
              "      <td>46</td>\n",
              "      <td>67</td>\n",
              "      <td>10</td>\n",
              "      <td>792</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>62</td>\n",
              "      <td>33</td>\n",
              "      <td>21</td>\n",
              "      <td>25</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>787</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>31</td>\n",
              "      <td>61</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>11</td>\n",
              "      <td>34</td>\n",
              "      <td>26</td>\n",
              "      <td>799</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d460328e-c5ad-465b-b89b-2a6119e35204')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d460328e-c5ad-465b-b89b-2a6119e35204 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d460328e-c5ad-465b-b89b-2a6119e35204');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cff366aa-f3fb-4667-8154-96909f448df5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cff366aa-f3fb-4667-8154-96909f448df5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cff366aa-f3fb-4667-8154-96909f448df5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"row_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          8,\n          1,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 219,\n        \"min\": 7,\n        \"max\": 717,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          62,\n          21,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 232,\n        \"min\": 1,\n        \"max\": 748,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          33,\n          748,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 169,\n        \"min\": 8,\n        \"max\": 575,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          8,\n          58,\n          68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 139,\n        \"min\": 10,\n        \"max\": 471,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          25,\n          10,\n          146\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 183,\n        \"min\": 2,\n        \"max\": 609,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          46,\n          7,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 188,\n        \"min\": 4,\n        \"max\": 617,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          6,\n          4,\n          617\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 238,\n        \"min\": 6,\n        \"max\": 786,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          6,\n          20,\n          36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 238,\n        \"min\": 9,\n        \"max\": 792,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          9,\n          13,\n          75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 244,\n        \"min\": 1,\n        \"max\": 787,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          787,\n          25,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 245,\n        \"min\": 5,\n        \"max\": 799,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          44,\n          144,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(trX, trY), (teX, teY) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "jiZd938d-og4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ind = 7102\n",
        "sample_image = teX[ind,:,:,:]\n",
        "\n",
        "pixels = sample_image.reshape((32,32,3))\n",
        "plt.imshow(pixels,cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "2CaAVu7n9qGq",
        "outputId": "73395bb1-848b-445a-de2c-9607e0f2b690"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('real label', np.argmax(teY[ind]))\n",
        "print('predicted label', np.argmax(labels_test_predicted[ind]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cO4NcDX_BgK",
        "outputId": "420aba3e-38fc-4931-bbe4-55d11152fef3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "real label 0\n",
            "predicted label 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7M1rrTmn_R79"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}