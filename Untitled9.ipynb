{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyObqoXPsowwx/Ja9+/eKxg/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1fba9bab0df24bc7b3c72043ad0c082e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec749d497dab43acbde1a0caa0be3492","IPY_MODEL_12e22e8f5aca491d9856a61eb46cf604","IPY_MODEL_c703e254299f4a5eb62e0836de342fc8"],"layout":"IPY_MODEL_66554361f0de471ba192a1e48b3d9cf1"}},"ec749d497dab43acbde1a0caa0be3492":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3760dd591db24359ba96c2fbdd9d9185","placeholder":"​","style":"IPY_MODEL_05ffbf4e6fe74b3784b31733c50caadf","value":"100%"}},"12e22e8f5aca491d9856a61eb46cf604":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e95b04b1b2024461823edca903718aa0","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb1fef86b14240558b0a86a81beb8094","value":10}},"c703e254299f4a5eb62e0836de342fc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0500ead395854d51813a52a80c302a61","placeholder":"​","style":"IPY_MODEL_47a226c4bd854290816e11efecb4d975","value":" 10/10 [01:39&lt;00:00, 10.06s/it]"}},"66554361f0de471ba192a1e48b3d9cf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3760dd591db24359ba96c2fbdd9d9185":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05ffbf4e6fe74b3784b31733c50caadf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e95b04b1b2024461823edca903718aa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb1fef86b14240558b0a86a81beb8094":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0500ead395854d51813a52a80c302a61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47a226c4bd854290816e11efecb4d975":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"358e8aa3a0724a1f954695529a6443bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ecb3ade09648498b83519302b2d14044","IPY_MODEL_4a069aae115b4f919edc10b941b0b854","IPY_MODEL_c2123c0691d246afafe87ec8d3410d66"],"layout":"IPY_MODEL_4181f146b36240e48892c8c108fc8b9a"}},"ecb3ade09648498b83519302b2d14044":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56492de1a32e4367aa5aa6199a515030","placeholder":"​","style":"IPY_MODEL_f8842e85e2274103bb002d0c2ddc7d3a","value":"100%"}},"4a069aae115b4f919edc10b941b0b854":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4e30c7e4a744fffa850943e677b1d1a","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6d30fe3ff264c8daa5bf61b0a7b5af9","value":10}},"c2123c0691d246afafe87ec8d3410d66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_698b177600774b77a0ec83150d3f580f","placeholder":"​","style":"IPY_MODEL_8cd24b06f7024846a1be2f284355d4ea","value":" 10/10 [04:46&lt;00:00, 28.67s/it]"}},"4181f146b36240e48892c8c108fc8b9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56492de1a32e4367aa5aa6199a515030":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8842e85e2274103bb002d0c2ddc7d3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4e30c7e4a744fffa850943e677b1d1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6d30fe3ff264c8daa5bf61b0a7b5af9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"698b177600774b77a0ec83150d3f580f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cd24b06f7024846a1be2f284355d4ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"id":"gCTRGKDD304j","executionInfo":{"status":"ok","timestamp":1701111703037,"user_tz":0,"elapsed":374,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"outputs":[],"source":["import torch\n","import torchvision\n","from pathlib import Path\n","from torchvision import transforms\n","from torch import nn"]},{"cell_type":"code","source":["!pip install torchinfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PPboDyWq5qrl","executionInfo":{"status":"ok","timestamp":1701111708927,"user_tz":0,"elapsed":5895,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}},"outputId":"4c004326-aeeb-4baa-acc1-8be00c8f9bfa"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"]}]},{"cell_type":"code","source":["from torchinfo import summary"],"metadata":{"id":"Rkadh-Ie544c","executionInfo":{"status":"ok","timestamp":1701111708928,"user_tz":0,"elapsed":12,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from helper_functions import download_data"],"metadata":{"id":"H6J25XcO59J2","executionInfo":{"status":"ok","timestamp":1701111708928,"user_tz":0,"elapsed":11,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"id":"CoSEeUHp8Xza","executionInfo":{"status":"ok","timestamp":1701111708928,"user_tz":0,"elapsed":11,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["transformer_encoder_layer = nn.TransformerEncoderLayer(d_model = 768,\n","                                                       nhead = 12,\n","                                                       dim_feedforward=3072,\n","                                                       dropout=0.1,\n","                                                       activation=\"gelu\",\n","                                                       batch_first=True,\n","                                                       norm_first=True)"],"metadata":{"id":"S_1mm_8g8eyz","executionInfo":{"status":"ok","timestamp":1701111709322,"user_tz":0,"elapsed":405,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class PatchEmbedding(nn.Module):\n","  def __init__(self,\n","               in_channels: int = 3,\n","               patch_size: int = 16,\n","               embedding_dim: int = 768):\n","    super().__init__()\n","\n","    self.patch_size = patch_size\n","\n","    self.patcher = nn.Conv2d(in_channels=in_channels,\n","                             out_channels=embedding_dim,\n","                             kernel_size=patch_size,\n","                             stride=patch_size,\n","                             padding=0)\n","\n","    self.flatten = nn.Flatten(start_dim=2,\n","                              end_dim=3)\n","\n","  def forward(self, x):\n","    image_resolution = x.shape[-1]\n","    assert image_resolution % self.patch_size == 0, f\"Image size must be divisible by patch_size. Image size: {image_resolution}, patch size: {self.patch_size}\"\n","\n","    x_patched = self.patcher(x)\n","    x_flattened = self.flatten(x_patched)\n","\n","    return x_flattened.permute(0, 2, 1)"],"metadata":{"id":"65kXbkemKXRc","executionInfo":{"status":"ok","timestamp":1701112674393,"user_tz":0,"elapsed":275,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class ViT(nn.Module):\n","  def __init__(self,\n","               img_size: int = 224,\n","               in_channels: int = 3,\n","               patch_size: int = 16,\n","               num_transformer_layers: int = 12,\n","               embedding_dim: int = 768,\n","               mlp_size: int = 3072,\n","               num_heads: int = 12,\n","               attn_dropout: float = 0.0,\n","               mlp_dropout: float = 0.1,\n","               embedding_dropout: float = 0.1,\n","               num_classes: int = 3):\n","    super().__init__()\n","\n","    assert img_size % patch_size == 0, f\"Image size must be divisible by patch size, image size: {img_size}, patch size: {patch_size}\"\n","\n","    self.num_patches = (img_size * img_size) // patch_size**2\n","\n","    self.class_embedding = nn.Parameter(data = torch.randn(1, 1, embedding_dim),\n","                                        requires_grad=True)\n","\n","    self.position_embedding = nn.Parameter(data=torch.randn(1,\n","                                                            self.num_patches+1,\n","                                                            embedding_dim),\n","                                           requires_grad=True)\n","\n","    self.embedding_dropout = nn.Dropout(p=embedding_dropout)\n","\n","    # patch embedding layer\n","    self.patch_embedding = PatchEmbedding(in_channels=in_channels,\n","                                          patch_size=patch_size,\n","                                          embedding_dim=embedding_dim)\n","\n","    self.transformer_encoder = nn.Sequential(*[transformer_encoder_layer for _ in range(num_transformer_layers)])\n","\n","    self.classifier = nn.Sequential(nn.LayerNorm(normalized_shape=embedding_dim),\n","                                    nn.Linear(in_features=embedding_dim,\n","                                              out_features=num_classes))\n","\n","  def forward(self, x):\n","    batch_size = x.shape[0]\n","\n","    class_token = self.class_embedding.expand(batch_size, -1, -1)\n","\n","    x = self.patch_embedding(x)\n","\n","    x = torch.cat((class_token, x), dim=1)\n","\n","    x = self.position_embedding + x\n","\n","    x = self.embedding_dropout(x)\n","\n","    x = self.transformer_encoder(x)\n","\n","    x = self.classifer(x[:, 0])\n","\n","    return x\n"],"metadata":{"id":"Et1uUyQB91JO","executionInfo":{"status":"ok","timestamp":1701112677899,"user_tz":0,"elapsed":305,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["vit = ViT()"],"metadata":{"id":"8H-2TpFsJ48w","executionInfo":{"status":"ok","timestamp":1701112683836,"user_tz":0,"elapsed":359,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["%%writefile vit.py\n","import torch\n","from torch import nn\n","\n","transformer_encoder_layer = nn.TransformerEncoderLayer(d_model = 768,\n","                                                       nhead = 12,\n","                                                       dim_feedforward=3072,\n","                                                       dropout=0.1,\n","                                                       activation=\"gelu\",\n","                                                       batch_first=True,\n","                                                       norm_first=True)\n","\n","class PatchEmbedding(nn.Module):\n","  def __init__(self,\n","               in_channels: int = 3,\n","               patch_size: int = 16,\n","               embedding_dim: int = 768):\n","    super().__init__()\n","\n","    self.patch_size = patch_size\n","\n","    self.patcher = nn.Conv2d(in_channels=in_channels,\n","                             out_channels=embedding_dim,\n","                             kernel_size=patch_size,\n","                             stride=patch_size,\n","                             padding=0)\n","\n","    self.flatten = nn.Flatten(start_dim=2,\n","                              end_dim=3)\n","\n","  def forward(self, x):\n","    image_resolution = x.shape[-1]\n","    assert image_resolution % self.patch_size == 0, f\"Image size must be divisible by patch_size. Image size: {image_resolution}, patch size: {self.patch_size}\"\n","\n","    x_patched = self.patcher(x)\n","    x_flattened = self.flatten(x_patched)\n","\n","    return x_flattened.permute(0, 2, 1)\n","\n","class ViT(nn.Module):\n","  def __init__(self,\n","               img_size: int = 224,\n","               in_channels: int = 3,\n","               patch_size: int = 16,\n","               num_transformer_layers: int = 12,\n","               embedding_dim: int = 768,\n","               mlp_size: int = 3072,\n","               num_heads: int = 12,\n","               attn_dropout: float = 0.0,\n","               mlp_dropout: float = 0.1,\n","               embedding_dropout: float = 0.1,\n","               num_classes: int = 3):\n","    super().__init__()\n","\n","    assert img_size % patch_size == 0, f\"Image size must be divisible by patch size, image size: {img_size}, patch size: {patch_size}\"\n","\n","    self.num_patches = (img_size * img_size) // patch_size**2\n","\n","    self.class_embedding = nn.Parameter(data = torch.randn(1, 1, embedding_dim),\n","                                        requires_grad=True)\n","\n","    self.position_embedding = nn.Parameter(data=torch.randn(1,\n","                                                            self.num_patches+1,\n","                                                            embedding_dim),\n","                                           requires_grad=True)\n","\n","    self.embedding_dropout = nn.Dropout(p=embedding_dropout)\n","\n","    # patch embedding layer\n","    self.patch_embedding = PatchEmbedding(in_channels=in_channels,\n","                                          patch_size=patch_size,\n","                                          embedding_dim=embedding_dim)\n","\n","    self.transformer_encoder = nn.Sequential(*[transformer_encoder_layer for _ in range(num_transformer_layers)])\n","\n","    self.classifier = nn.Sequential(nn.LayerNorm(normalized_shape=embedding_dim),\n","                                    nn.Linear(in_features=embedding_dim,\n","                                              out_features=num_classes))\n","\n","  def forward(self, x):\n","    batch_size = x.shape[0]\n","\n","    class_token = self.class_embedding.expand(batch_size, -1, -1)\n","\n","    x = self.patch_embedding(x)\n","\n","    x = torch.cat((class_token, x), dim=1)\n","\n","    x = self.position_embedding + x\n","\n","    x = self.embedding_dropout(x)\n","\n","    x = self.transformer_encoder(x)\n","\n","    x = self.classifer(x[:, 0])\n","\n","    return x\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpDsXORMKPy1","executionInfo":{"status":"ok","timestamp":1701113159485,"user_tz":0,"elapsed":6,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}},"outputId":"4533ed02-bf8c-4026-f8a9-edb786299992"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting vit.py\n"]}]},{"cell_type":"code","source":["from vit import ViT as ViT_import"],"metadata":{"id":"G4gM9LK1PMnq","executionInfo":{"status":"ok","timestamp":1701113162687,"user_tz":0,"elapsed":5,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["vit = ViT_import()"],"metadata":{"id":"da8zPQwzPahq","executionInfo":{"status":"ok","timestamp":1701113177018,"user_tz":0,"elapsed":6,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["from get_data import download_data\n","\n","url = \"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\"\n","\n","images_path = download_data(url,\n","                            target_directory=\"pizza_steak_sushi_20\")\n","\n","train_dir = images_path / \"train\"\n","test_dir = images_path / \"test\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SZVHNZuCPx7R","executionInfo":{"status":"ok","timestamp":1701113671150,"user_tz":0,"elapsed":1483,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}},"outputId":"16525216-e521-4b81-98bb-ca5ff55ed5f0"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating data/pizza_steak_sushi_20\n","Downloading pizza_steak_sushi_20_percent.zip...\n","Unzipping pizza_steak_sushi_20_percent.zip...\n"]}]},{"cell_type":"code","source":["pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n","pretrained_vit_transforms = pretrained_vit_weights.transforms()\n","\n","pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights).to(device)"],"metadata":{"id":"Mo94-m34RGRh","executionInfo":{"status":"ok","timestamp":1701114136495,"user_tz":0,"elapsed":1509,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["for parameter in pretrained_vit.parameters():\n","  parameter.requires_grad = False"],"metadata":{"id":"hdkiiFFeSnxd","executionInfo":{"status":"ok","timestamp":1701114145263,"user_tz":0,"elapsed":267,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["import data_setup\n","\n","BATCH_SIZE = 32\n","\n","train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir,\n","                                                                               test_dir,\n","                                                                               pretrained_vit_transforms,\n","                                                                               pretrained_vit_transforms,\n","                                                                               BATCH_SIZE)\n"],"metadata":{"id":"m_kWQ8PpTeZr","executionInfo":{"status":"ok","timestamp":1701114531399,"user_tz":0,"elapsed":3,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["pretrained_vit.heads = nn.Linear(in_features=768, out_features=len(class_names))\n","\n","pretrained_vit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaHkqII_U8sI","executionInfo":{"status":"ok","timestamp":1701114608303,"user_tz":0,"elapsed":3,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}},"outputId":"d05af5e8-3058-4be4-8ad3-c47fcbef6d4d"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VisionTransformer(\n","  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","  (encoder): Encoder(\n","    (dropout): Dropout(p=0.0, inplace=False)\n","    (layers): Sequential(\n","      (encoder_layer_0): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_1): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_2): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_3): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_4): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_5): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_6): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_7): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_8): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_9): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_10): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","      (encoder_layer_11): EncoderBlock(\n","        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (self_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","        (mlp): MLPBlock(\n","          (0): Linear(in_features=768, out_features=3072, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Dropout(p=0.0, inplace=False)\n","          (3): Linear(in_features=3072, out_features=768, bias=True)\n","          (4): Dropout(p=0.0, inplace=False)\n","        )\n","      )\n","    )\n","    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","  )\n","  (heads): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["summary(model=pretrained_vit,\n","        input_size=(1, 3, 224, 224),\n","        col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\"),\n","        col_width=20,\n","        row_settings=[\"var_names\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3qmhxKUOVLUj","executionInfo":{"status":"ok","timestamp":1701114779058,"user_tz":0,"elapsed":6183,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}},"outputId":"dca417e6-a05c-4a5b-e347-5d8318ca1fc3"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["============================================================================================================================================\n","Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n","============================================================================================================================================\n","VisionTransformer (VisionTransformer)                        [1, 3, 224, 224]     [1, 3]               768                  Partial\n","├─Conv2d (conv_proj)                                         [1, 3, 224, 224]     [1, 768, 14, 14]     (590,592)            False\n","├─Encoder (encoder)                                          [1, 197, 768]        [1, 197, 768]        151,296              False\n","│    └─Dropout (dropout)                                     [1, 197, 768]        [1, 197, 768]        --                   --\n","│    └─Sequential (layers)                                   [1, 197, 768]        [1, 197, 768]        --                   False\n","│    │    └─EncoderBlock (encoder_layer_0)                   [1, 197, 768]        [1, 197, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_1)                   [1, 197, 768]        [1, 197, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_2)                   [1, 197, 768]        [1, 197, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_3)                   [1, 197, 768]        [1, 197, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_4)                   [1, 197, 768]        [1, 197, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_5)                   [1, 197, 768]        [1, 197, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_6)                   [1, 197, 768]        [1, 197, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_7)                   [1, 197, 768]        [1, 197, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_8)                   [1, 197, 768]        [1, 197, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_9)                   [1, 197, 768]        [1, 197, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_10)                  [1, 197, 768]        [1, 197, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_11)                  [1, 197, 768]        [1, 197, 768]        (7,087,872)          False\n","│    └─LayerNorm (ln)                                        [1, 197, 768]        [1, 197, 768]        (1,536)              False\n","├─Linear (heads)                                             [1, 768]             [1, 3]               2,307                True\n","============================================================================================================================================\n","Total params: 85,800,963\n","Trainable params: 2,307\n","Non-trainable params: 85,798,656\n","Total mult-adds (M): 172.47\n","============================================================================================================================================\n","Input size (MB): 0.60\n","Forward/backward pass size (MB): 104.09\n","Params size (MB): 229.20\n","Estimated Total Size (MB): 333.89\n","============================================================================================================================================"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["import engine\n","\n","EPOCHS = 10\n","\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(pretrained_vit.parameters(),\n","                             lr=0.001)\n","\n","pretrained_vit_results = engine.train(pretrained_vit,\n","                                      train_dataloader,\n","                                      test_dataloader,\n","                                      optimizer,\n","                                      loss_fn,\n","                                      EPOCHS,\n","                                      device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":234,"referenced_widgets":["1fba9bab0df24bc7b3c72043ad0c082e","ec749d497dab43acbde1a0caa0be3492","12e22e8f5aca491d9856a61eb46cf604","c703e254299f4a5eb62e0836de342fc8","66554361f0de471ba192a1e48b3d9cf1","3760dd591db24359ba96c2fbdd9d9185","05ffbf4e6fe74b3784b31733c50caadf","e95b04b1b2024461823edca903718aa0","eb1fef86b14240558b0a86a81beb8094","0500ead395854d51813a52a80c302a61","47a226c4bd854290816e11efecb4d975"]},"id":"fdxf18BZV3rs","executionInfo":{"status":"ok","timestamp":1701115172667,"user_tz":0,"elapsed":100351,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}},"outputId":"2b3b1d66-9225-4890-b6e6-7a41f4f9ccf3"},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fba9bab0df24bc7b3c72043ad0c082e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epochs: 0 | Train Loss: 0.726 | Train Acc: 71.04% | Test Loss: 0.268 | Test Acc: 94.38%\n","Epochs: 1 | Train Loss: 0.248 | Train Acc: 93.54% | Test Loss: 0.153 | Test Acc: 95.97%\n","Epochs: 2 | Train Loss: 0.169 | Train Acc: 95.42% | Test Loss: 0.108 | Test Acc: 98.12%\n","Epochs: 3 | Train Loss: 0.139 | Train Acc: 96.25% | Test Loss: 0.091 | Test Acc: 98.12%\n","Epochs: 4 | Train Loss: 0.133 | Train Acc: 97.08% | Test Loss: 0.082 | Test Acc: 98.12%\n","Epochs: 5 | Train Loss: 0.117 | Train Acc: 97.08% | Test Loss: 0.077 | Test Acc: 98.75%\n","Epochs: 6 | Train Loss: 0.088 | Train Acc: 97.29% | Test Loss: 0.074 | Test Acc: 98.12%\n","Epochs: 7 | Train Loss: 0.080 | Train Acc: 97.71% | Test Loss: 0.067 | Test Acc: 98.12%\n","Epochs: 8 | Train Loss: 0.070 | Train Acc: 98.33% | Test Loss: 0.063 | Test Acc: 98.75%\n","Epochs: 9 | Train Loss: 0.063 | Train Acc: 98.75% | Test Loss: 0.060 | Test Acc: 98.12%\n"]}]},{"cell_type":"code","source":["swag_vit_weights = torchvision.models.ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1\n","swag_vit_transforms = swag_vit_weights.transforms()\n","\n","swag_vit = torchvision.models.vit_b_16(weights=swag_vit_weights).to(device)\n","\n","for parameter in swag_vit.parameters():\n","  parameter.requires_grad = False"],"metadata":{"id":"k7srdbDuXAzy","executionInfo":{"status":"ok","timestamp":1701116333205,"user_tz":0,"elapsed":1789,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["swag_train_dataloader, swag_test_dataloader, class_names = data_setup.create_dataloaders(train_dir,\n","                                                                                         test_dir,\n","                                                                                         swag_vit_transforms,\n","                                                                                         swag_vit_transforms,\n","                                                                                         BATCH_SIZE)"],"metadata":{"id":"bvdieybBYkPR","executionInfo":{"status":"ok","timestamp":1701116337059,"user_tz":0,"elapsed":374,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["summary(model=swag_vit,\n","        input_size=(1, 3, 384, 384),\n","        col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\"),\n","        col_width=20,\n","        row_settings=[\"var_names\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vlmrt90CZ8_q","executionInfo":{"status":"ok","timestamp":1701116339633,"user_tz":0,"elapsed":5,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}},"outputId":"ec876056-2be0-4189-cac1-80790e4bb364"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["============================================================================================================================================\n","Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n","============================================================================================================================================\n","VisionTransformer (VisionTransformer)                        [1, 3, 384, 384]     [1, 1000]            768                  False\n","├─Conv2d (conv_proj)                                         [1, 3, 384, 384]     [1, 768, 24, 24]     (590,592)            False\n","├─Encoder (encoder)                                          [1, 577, 768]        [1, 577, 768]        443,136              False\n","│    └─Dropout (dropout)                                     [1, 577, 768]        [1, 577, 768]        --                   --\n","│    └─Sequential (layers)                                   [1, 577, 768]        [1, 577, 768]        --                   False\n","│    │    └─EncoderBlock (encoder_layer_0)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_1)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_2)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_3)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_4)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_5)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_6)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_7)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_8)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_9)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_10)                  [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_11)                  [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    └─LayerNorm (ln)                                        [1, 577, 768]        [1, 577, 768]        (1,536)              False\n","├─Sequential (heads)                                         [1, 768]             [1, 1000]            --                   False\n","│    └─Linear (head)                                         [1, 768]             [1, 1000]            (769,000)            False\n","============================================================================================================================================\n","Total params: 86,859,496\n","Trainable params: 0\n","Non-trainable params: 86,859,496\n","Total mult-adds (M): 397.66\n","============================================================================================================================================\n","Input size (MB): 1.77\n","Forward/backward pass size (MB): 304.88\n","Params size (MB): 232.27\n","Estimated Total Size (MB): 538.92\n","============================================================================================================================================"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["swag_vit.heads = nn.Linear(in_features=768, out_features=len(class_names))"],"metadata":{"id":"I1SUpkxZalRY","executionInfo":{"status":"ok","timestamp":1701116346629,"user_tz":0,"elapsed":2,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["summary(model=swag_vit,\n","        input_size=(1, 3, 384, 384),\n","        col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\"),\n","        col_width=20,\n","        row_settings=[\"var_names\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SRjoPTaCbYVB","executionInfo":{"status":"ok","timestamp":1701116353784,"user_tz":0,"elapsed":362,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}},"outputId":"fd8962d3-402c-4fec-bc28-16afe9163854"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["============================================================================================================================================\n","Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n","============================================================================================================================================\n","VisionTransformer (VisionTransformer)                        [1, 3, 384, 384]     [1, 3]               768                  Partial\n","├─Conv2d (conv_proj)                                         [1, 3, 384, 384]     [1, 768, 24, 24]     (590,592)            False\n","├─Encoder (encoder)                                          [1, 577, 768]        [1, 577, 768]        443,136              False\n","│    └─Dropout (dropout)                                     [1, 577, 768]        [1, 577, 768]        --                   --\n","│    └─Sequential (layers)                                   [1, 577, 768]        [1, 577, 768]        --                   False\n","│    │    └─EncoderBlock (encoder_layer_0)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_1)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_2)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_3)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_4)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_5)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_6)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_7)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_8)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_9)                   [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_10)                  [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    │    └─EncoderBlock (encoder_layer_11)                  [1, 577, 768]        [1, 577, 768]        (7,087,872)          False\n","│    └─LayerNorm (ln)                                        [1, 577, 768]        [1, 577, 768]        (1,536)              False\n","├─Linear (heads)                                             [1, 768]             [1, 3]               2,307                True\n","============================================================================================================================================\n","Total params: 86,092,803\n","Trainable params: 2,307\n","Non-trainable params: 86,090,496\n","Total mult-adds (M): 396.89\n","============================================================================================================================================\n","Input size (MB): 1.77\n","Forward/backward pass size (MB): 304.87\n","Params size (MB): 229.20\n","Estimated Total Size (MB): 535.84\n","============================================================================================================================================"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["swag_optimizer = torch.optim.Adam(swag_vit.parameters(),\n","                             lr=0.001)\n","\n","engine.train(swag_vit,\n","             swag_train_dataloader,\n","             swag_test_dataloader,\n","             swag_optimizer,\n","             loss_fn,\n","             EPOCHS,\n","             device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":806,"referenced_widgets":["358e8aa3a0724a1f954695529a6443bb","ecb3ade09648498b83519302b2d14044","4a069aae115b4f919edc10b941b0b854","c2123c0691d246afafe87ec8d3410d66","4181f146b36240e48892c8c108fc8b9a","56492de1a32e4367aa5aa6199a515030","f8842e85e2274103bb002d0c2ddc7d3a","b4e30c7e4a744fffa850943e677b1d1a","b6d30fe3ff264c8daa5bf61b0a7b5af9","698b177600774b77a0ec83150d3f580f","8cd24b06f7024846a1be2f284355d4ea"]},"id":"HsgOHmNtbjMS","executionInfo":{"status":"ok","timestamp":1701116987751,"user_tz":0,"elapsed":287329,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}},"outputId":"0ffb50fb-37d5-4a5b-e34f-1672bc65c7bb"},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"358e8aa3a0724a1f954695529a6443bb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epochs: 0 | Train Loss: 0.379 | Train Acc: 87.08% | Test Loss: 0.040 | Test Acc: 100.00%\n","Epochs: 1 | Train Loss: 0.061 | Train Acc: 98.12% | Test Loss: 0.012 | Test Acc: 100.00%\n","Epochs: 2 | Train Loss: 0.038 | Train Acc: 98.54% | Test Loss: 0.008 | Test Acc: 100.00%\n","Epochs: 3 | Train Loss: 0.026 | Train Acc: 99.38% | Test Loss: 0.007 | Test Acc: 100.00%\n","Epochs: 4 | Train Loss: 0.019 | Train Acc: 99.79% | Test Loss: 0.007 | Test Acc: 100.00%\n","Epochs: 5 | Train Loss: 0.014 | Train Acc: 99.79% | Test Loss: 0.006 | Test Acc: 100.00%\n","Epochs: 6 | Train Loss: 0.011 | Train Acc: 99.79% | Test Loss: 0.006 | Test Acc: 100.00%\n","Epochs: 7 | Train Loss: 0.009 | Train Acc: 100.00% | Test Loss: 0.005 | Test Acc: 100.00%\n","Epochs: 8 | Train Loss: 0.008 | Train Acc: 100.00% | Test Loss: 0.005 | Test Acc: 100.00%\n","Epochs: 9 | Train Loss: 0.007 | Train Acc: 100.00% | Test Loss: 0.004 | Test Acc: 100.00%\n"]},{"output_type":"execute_result","data":{"text/plain":["{'train_loss': [0.3791725266414384,\n","  0.060845239673896385,\n","  0.03773432287077109,\n","  0.02574083979707211,\n","  0.01920426142460201,\n","  0.014374229571937272,\n","  0.01129259168325613,\n","  0.009201703205083808,\n","  0.007669865623271713,\n","  0.006519828321567426],\n"," 'train_acc': [0.8708333333333333,\n","  0.98125,\n","  0.9854166666666667,\n","  0.99375,\n","  0.9979166666666667,\n","  0.9979166666666667,\n","  0.9979166666666667,\n","  1.0,\n","  1.0,\n","  1.0],\n"," 'test_loss': [0.040079341270029545,\n","  0.012161548167932778,\n","  0.008372983278241009,\n","  0.0073016483045648785,\n","  0.006946713998331688,\n","  0.006307534044026397,\n","  0.005544812249718234,\n","  0.005006687316927128,\n","  0.004512662460911088,\n","  0.0041628509236034],\n"," 'test_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["!cd / && find -name \"*pth\" -type \"f\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lPEVFAikdDE6","executionInfo":{"status":"ok","timestamp":1701117737302,"user_tz":0,"elapsed":6195,"user":{"displayName":"Leslie Tetteh","userId":"07807436207377221344"}},"outputId":"67b4a1eb-ad82-4916-f675-52d22eea34a2"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["./sys/devices/pci0000:00/0000:00:03.0/virtio0/host0/target0:0:1/0:0:1:0/queue_depth\n","./sys/fs/cgroup/cgroup.max.depth\n","./sys/module/nvme/parameters/io_queue_depth\n","./sys/module/dm_mod/parameters/dm_mq_queue_depth\n","./proc/sys/kernel/max_lock_depth\n","./proc/driver/nvidia/suspend_depth\n","find: ‘./proc/53/task/53/net’: Invalid argument\n","find: ‘./proc/53/net’: Invalid argument\n","find: ‘./proc/26910’: No such file or directory\n","./var/colab/cgroup/jupyter-children/cgroup.max.depth\n","./root/.cache/torch/hub/checkpoints/vit_b_16_swag-9ac1b537.pth\n","./root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n","./usr/local/lib/python3.10/dist-packages/google_colab-1.0.0-py3.10-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_api_core-2.11.1-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_auth-2.17.3-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_cloud_language-2.9.1-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/matplotlib-3.7.1-py3.10-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_cloud_firestore-2.11.1-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_cloud_bigquery_storage-2.22.0-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_generativeai-0.2.2-py3.11-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_cloud_resource_manager-1.10.4-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_cloud_bigquery_connection-1.12.1-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_cloud_functions-1.13.3-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_cloud_translate-3.11.3-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_cloud_core-2.3.3-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_cloud_datastore-2.15.2-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/sphinxcontrib_jsmath-1.0.1-py3.7-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/googleapis_common_protos-1.61.0-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_cloud_storage-2.8.0-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/grpc_google_iam_v1-0.12.7-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_cloud_iam-2.12.2-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_ai_generativelanguage-0.3.3-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/google_cloud_bigquery-3.12.0-py3.9-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/protobuf-3.20.3-py3.10-nspkg.pth\n","./usr/local/lib/python3.10/dist-packages/distutils-precedence.pth\n","./tools/google-cloud-sdk/platform/bundledpythonunix/lib/python3.11/site-packages/distutils-precedence.pth\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8Rm1NzAog73O"},"execution_count":null,"outputs":[]}]}